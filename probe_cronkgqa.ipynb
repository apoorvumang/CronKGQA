{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enclosed-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Dict\n",
    "import logging\n",
    "import torch\n",
    "from torch import optim\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from qa_models import QA_model, QA_model_Only_Embeddings, QA_model_BERT, QA_model_EaE, QA_model_EmbedKGQA, QA_model_EaE_replace, QA_model_EmbedKGQA_complex\n",
    "from qa_datasets import QA_Dataset, QA_Dataset_model1, QA_Dataset_EaE, QA_Dataset_EmbedKGQA, QA_Dataset_EaE_replace\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import utils\n",
    "from tqdm import tqdm\n",
    "from utils import loadTkbcModel, loadTkbcModel_complex\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "actual-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "illegal-friendship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tkbc model from models/wikidata_big/kg_embeddings/tkbc_model_17dec.ckpt\n",
      "Number ent,rel,ts from loaded model: 125726 406 9621\n",
      "Loaded tkbc model\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'wikidata_big'\n",
    "tkbc_model_file = 'tkbc_model_17dec.ckpt'\n",
    "tkbc_model = loadTkbcModel('models/{dataset_name}/kg_embeddings/{tkbc_model_file}'.format(\n",
    "    dataset_name = dataset_name, tkbc_model_file=tkbc_model_file\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "federal-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    lm_frozen = 1\n",
    "    frozen = 1\n",
    "    multi_label=0\n",
    "    combine_all_ents = 'None'\n",
    "    attention = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "communist-hanging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing LM params\n",
      "Freezing entity/time embeddings\n",
      "Loading model from models/wikidata_big/qa_models/cronkgqa_finalds2.ckpt\n",
      "Loaded qa model from  models/wikidata_big/qa_models/cronkgqa_finalds2.ckpt\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "qa_model = QA_model_EmbedKGQA(tkbc_model, args)\n",
    "filename = 'models/{dataset_name}/qa_models/{model_file}.ckpt'.format(\n",
    "    dataset_name=dataset_name,\n",
    "    model_file='cronkgqa_finalds2'\n",
    ")\n",
    "print('Loading model from', filename)\n",
    "# add cpu thing here if no gpu available\n",
    "qa_model.load_state_dict(torch.load(filename))\n",
    "print('Loaded qa model from ', filename)\n",
    "qa_model = qa_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "694d75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeProbeData(dataset):\n",
    "    filtered_questions = []\n",
    "    for q in dataset.data:\n",
    "        question_type = q['type']\n",
    "        answer_type = q['answer_type']\n",
    "        entities = q['entities']\n",
    "        paraphrases = q['paraphrases']\n",
    "        if question_type == 'first_last' and answer_type == 'time' and len(entities) == 1:\n",
    "            is_first = False\n",
    "            for pp in paraphrases:\n",
    "                if 'first' in pp:\n",
    "                    is_first = True\n",
    "                    break\n",
    "            if is_first:\n",
    "                filtered_questions.append(q)\n",
    "    final_data = []\n",
    "    for q in filtered_questions:\n",
    "        rel = list(q['relations'])[0]\n",
    "        ent = list(q['entities'])[0]\n",
    "        answer = list(q['answers'])[0]\n",
    "        item = {}\n",
    "        item['relation_id'] = dataset.all_dicts['rel2id'][rel]\n",
    "        item['entity_id'] = dataset.all_dicts['ent2id'][ent]\n",
    "        item['time'] = int(answer)\n",
    "        final_data.append(item)\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    # do device cpu if no gpu\n",
    "    device = torch.device('cuda:0')\n",
    "    for item in final_data:\n",
    "        relation_id = torch.tensor([item['relation_id']]).long().to(device)\n",
    "        rel_vector = tkbc_model.embeddings[1](relation_id)[0].cpu().numpy()\n",
    "        entity_id = torch.tensor([item['entity_id']]).long().to(device)\n",
    "        ent_vector = tkbc_model.embeddings[0](entity_id)[0].cpu().numpy()\n",
    "        input_vector = np.concatenate((rel_vector, ent_vector))\n",
    "        X_list.append(input_vector)\n",
    "        time = item['time']\n",
    "        y = time\n",
    "        y_list.append(y)\n",
    "    X_data = np.array(X_list)\n",
    "    y_data = np.array(y_list)\n",
    "    \n",
    "    return X_data, y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95e2a17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions =  350000\n",
      "Preparing data for split train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10237, 1024), (10237,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = QA_Dataset_EmbedKGQA(split='train', dataset_name=dataset_name)\n",
    "X_train, y_train = makeProbeData(train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b90e9296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions =  30000\n",
      "Preparing data for split valid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1060, 1024), (1060,))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = QA_Dataset_EmbedKGQA(split='valid', dataset_name=dataset_name)\n",
    "X_valid, y_valid = makeProbeData(valid)\n",
    "X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e0d8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "X, y = X_train, y_train\n",
    "rf = RandomForestRegressor(n_estimators=500, oob_score=True, random_state=100, verbose=1)\n",
    "reg = rf.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ca05eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('probe_randomforest_regressor_fulltrain.pkl', 'wb') as fid:\n",
    "    pickle.dump(reg, fid)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "733ae97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "027a9c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1975.49]), 1983)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 4\n",
    "reg.predict([X_valid[id]]), y_valid[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a6a1c694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1060/1060 [00:42<00:00, 24.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77.49095063461692"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "exact = 0\n",
    "error = 0\n",
    "predictor = reg\n",
    "predictions = []\n",
    "for id in tqdm(range(len(X_valid))):\n",
    "    pred = predictor.predict([X_valid[id]])[0]\n",
    "    true = y_valid[id]\n",
    "    predictions.append(pred)\n",
    "    error += (pred - true)**2\n",
    "math.sqrt(error/len(X_valid) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5ace41ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47924528301886793"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = 0\n",
    "total = len(X_valid)\n",
    "gap = 3\n",
    "for i in range(len(predictions)):\n",
    "    pred = predictions[i]\n",
    "    true = y_valid[i]\n",
    "    range_low, range_high = true - gap, true + gap\n",
    "    if pred >= range_low and pred <= range_high:\n",
    "        num_correct += 1\n",
    "num_correct/total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
