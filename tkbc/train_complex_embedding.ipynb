{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Dict\n",
    "import logging\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from datasets import TemporalDataset\n",
    "from optimizers import TKBCOptimizer, IKBCOptimizer\n",
    "from models import ComplEx, TComplEx, TNTComplEx\n",
    "from regularizers import N3, Lambda3\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed number of timestamps (from default script)\n",
      "Number of entity, rel, time\n",
      "125726 406 9621\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# create model\n",
    "# this resets the model\n",
    "\n",
    "import argparse\n",
    "from typing import Dict\n",
    "import logging\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from datasets import TemporalDataset\n",
    "from optimizers import TKBCOptimizer, IKBCOptimizer\n",
    "from models import ComplEx, TComplEx, TNTComplEx\n",
    "from regularizers import N3, Lambda3\n",
    "\n",
    "\n",
    "class Args:\n",
    "    dataset =  'wikidata_big'\n",
    "    model =  'ComplEx'\n",
    "    max_epochs = 50\n",
    "    valid_freq = 5\n",
    "    rank = 256\n",
    "    batch_size = 512\n",
    "    learning_rate = 1e-2\n",
    "    emb_reg = 0.01\n",
    "    time_reg = 0.01\n",
    "    no_time_emb = False\n",
    "    \n",
    "args=Args()\n",
    "\n",
    "dataset = TemporalDataset(args.dataset)\n",
    "\n",
    "sizes = dataset.get_shape()\n",
    "model = {\n",
    "    'ComplEx': ComplEx(sizes, args.rank),\n",
    "    'TComplEx': TComplEx(sizes, args.rank, no_time_emb=args.no_time_emb),\n",
    "    'TNTComplEx': TNTComplEx(sizes, args.rank, no_time_emb=args.no_time_emb),\n",
    "}[args.model]\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "opt = optim.Adagrad(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "emb_reg = N3(args.emb_reg)\n",
    "time_reg = Lambda3(args.time_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9147.74ex/s, cont=0.0000, loss=4, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9118.19ex/s, cont=0.0000, loss=4, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9139.98ex/s, cont=0.0000, loss=4, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9126.20ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9125.87ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss:   0%|          | 1024/645976 [00:00<01:16, 8431.54ex/s, cont=0.0000, loss=4, loss_time=0, reg=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  {'MRR_full_time': 0.659314751625061, 'MRR_all': 0.659314751625061, 'hits@_full_time': tensor([0.5125, 0.7672, 0.9255]), 'hits@_all': tensor([0.5125, 0.7672, 0.9255])}\n",
      "test:  {'MRR_full_time': 0.307646781206131, 'MRR_all': 0.307646781206131, 'hits@_full_time': tensor([0.2014, 0.3351, 0.5371]), 'hits@_all': tensor([0.2014, 0.3351, 0.5371])}\n",
      "train:  {'MRR_full_time': 0.6541852951049805, 'MRR_all': 0.6541852951049805, 'hits@_full_time': tensor([0.5074, 0.7618, 0.9216]), 'hits@_all': tensor([0.5074, 0.7618, 0.9216])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9102.24ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9095.61ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9115.70ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9105.17ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9119.19ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss:   0%|          | 1024/645976 [00:00<01:16, 8482.08ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  {'MRR_full_time': 0.6670675873756409, 'MRR_all': 0.6670675873756409, 'hits@_full_time': tensor([0.5203, 0.7762, 0.9321]), 'hits@_all': tensor([0.5203, 0.7762, 0.9321])}\n",
      "test:  {'MRR_full_time': 0.3085794746875763, 'MRR_all': 0.3085794746875763, 'hits@_full_time': tensor([0.2030, 0.3355, 0.5395]), 'hits@_all': tensor([0.2030, 0.3355, 0.5395])}\n",
      "train:  {'MRR_full_time': 0.659308671951294, 'MRR_all': 0.659308671951294, 'hits@_full_time': tensor([0.5106, 0.7717, 0.9278]), 'hits@_all': tensor([0.5106, 0.7717, 0.9278])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9151.98ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9128.29ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9111.59ex/s, cont=0.0000, loss=4, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9086.16ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9105.29ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss:   0%|          | 1024/645976 [00:00<01:17, 8355.09ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  {'MRR_full_time': 0.6711758375167847, 'MRR_all': 0.6711758375167847, 'hits@_full_time': tensor([0.5245, 0.7824, 0.9357]), 'hits@_all': tensor([0.5245, 0.7824, 0.9357])}\n",
      "test:  {'MRR_full_time': 0.30873364210128784, 'MRR_all': 0.30873364210128784, 'hits@_full_time': tensor([0.2028, 0.3351, 0.5427]), 'hits@_all': tensor([0.2028, 0.3351, 0.5427])}\n",
      "train:  {'MRR_full_time': 0.6629024744033813, 'MRR_all': 0.6629024744033813, 'hits@_full_time': tensor([0.5133, 0.7769, 0.9334]), 'hits@_all': tensor([0.5133, 0.7769, 0.9334])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9106.71ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9099.79ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9134.42ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9125.80ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9111.81ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss:   0%|          | 1024/645976 [00:00<01:18, 8239.89ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  {'MRR_full_time': 0.6745040416717529, 'MRR_all': 0.6745040416717529, 'hits@_full_time': tensor([0.5255, 0.7882, 0.9379]), 'hits@_all': tensor([0.5255, 0.7882, 0.9379])}\n",
      "test:  {'MRR_full_time': 0.3079131245613098, 'MRR_all': 0.3079131245613098, 'hits@_full_time': tensor([0.2014, 0.3345, 0.5439]), 'hits@_all': tensor([0.2014, 0.3345, 0.5439])}\n",
      "train:  {'MRR_full_time': 0.6651384234428406, 'MRR_all': 0.6651384234428406, 'hits@_full_time': tensor([0.5134, 0.7804, 0.9397]), 'hits@_all': tensor([0.5134, 0.7804, 0.9397])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9098.02ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9092.22ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9111.27ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9107.81ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9098.44ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss:   0%|          | 1024/645976 [00:00<01:16, 8473.61ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  {'MRR_full_time': 0.6780468821525574, 'MRR_all': 0.6780468821525574, 'hits@_full_time': tensor([0.5300, 0.7918, 0.9417]), 'hits@_all': tensor([0.5300, 0.7918, 0.9417])}\n",
      "test:  {'MRR_full_time': 0.30807462334632874, 'MRR_all': 0.30807462334632874, 'hits@_full_time': tensor([0.2020, 0.3331, 0.5425]), 'hits@_all': tensor([0.2020, 0.3331, 0.5425])}\n",
      "train:  {'MRR_full_time': 0.6693954467773438, 'MRR_all': 0.6693954467773438, 'hits@_full_time': tensor([0.5196, 0.7837, 0.9395]), 'hits@_all': tensor([0.5196, 0.7837, 0.9395])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9155.47ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9111.13ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9108.13ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9092.60ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9068.07ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss:   0%|          | 1024/645976 [00:00<01:16, 8393.48ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  {'MRR_full_time': 0.6793134808540344, 'MRR_all': 0.6793134808540344, 'hits@_full_time': tensor([0.5300, 0.7938, 0.9437]), 'hits@_all': tensor([0.5300, 0.7938, 0.9437])}\n",
      "test:  {'MRR_full_time': 0.307550847530365, 'MRR_all': 0.307550847530365, 'hits@_full_time': tensor([0.2008, 0.3349, 0.5447]), 'hits@_all': tensor([0.2008, 0.3349, 0.5447])}\n",
      "train:  {'MRR_full_time': 0.6683575510978699, 'MRR_all': 0.6683575510978699, 'hits@_full_time': tensor([0.5168, 0.7840, 0.9415]), 'hits@_all': tensor([0.5168, 0.7840, 0.9415])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9057.30ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9097.33ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9131.57ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9100.35ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9061.94ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss:   0%|          | 1024/645976 [00:00<01:16, 8392.90ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  {'MRR_full_time': 0.681463897228241, 'MRR_all': 0.681463897228241, 'hits@_full_time': tensor([0.5326, 0.7972, 0.9445]), 'hits@_all': tensor([0.5326, 0.7972, 0.9445])}\n",
      "test:  {'MRR_full_time': 0.30734649300575256, 'MRR_all': 0.30734649300575256, 'hits@_full_time': tensor([0.2004, 0.3329, 0.5461]), 'hits@_all': tensor([0.2004, 0.3329, 0.5461])}\n",
      "train:  {'MRR_full_time': 0.6679976582527161, 'MRR_all': 0.6679976582527161, 'hits@_full_time': tensor([0.5152, 0.7842, 0.9432]), 'hits@_all': tensor([0.5152, 0.7842, 0.9432])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9081.71ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9087.72ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9094.89ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9096.91ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9147.59ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss:   0%|          | 1024/645976 [00:00<01:15, 8570.62ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  {'MRR_full_time': 0.6837716102600098, 'MRR_all': 0.6837716102600098, 'hits@_full_time': tensor([0.5364, 0.7966, 0.9455]), 'hits@_all': tensor([0.5364, 0.7966, 0.9455])}\n",
      "test:  {'MRR_full_time': 0.30729761719703674, 'MRR_all': 0.30729761719703674, 'hits@_full_time': tensor([0.2006, 0.3315, 0.5467]), 'hits@_all': tensor([0.2006, 0.3315, 0.5467])}\n",
      "train:  {'MRR_full_time': 0.6755523681640625, 'MRR_all': 0.6755523681640625, 'hits@_full_time': tensor([0.5247, 0.7926, 0.9461]), 'hits@_all': tensor([0.5247, 0.7926, 0.9461])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 100%|██████████| 645976/645976 [01:10<00:00, 9130.53ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9066.62ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9077.08ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9077.57ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9088.72ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss:   0%|          | 1024/645976 [00:00<01:17, 8362.48ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  {'MRR_full_time': 0.6834129095077515, 'MRR_all': 0.6834129095077515, 'hits@_full_time': tensor([0.5350, 0.7968, 0.9457]), 'hits@_all': tensor([0.5350, 0.7968, 0.9457])}\n",
      "test:  {'MRR_full_time': 0.30781400203704834, 'MRR_all': 0.30781400203704834, 'hits@_full_time': tensor([0.2016, 0.3313, 0.5487]), 'hits@_all': tensor([0.2016, 0.3313, 0.5487])}\n",
      "train:  {'MRR_full_time': 0.6715445518493652, 'MRR_all': 0.6715445518493652, 'hits@_full_time': tensor([0.5186, 0.7906, 0.9465]), 'hits@_all': tensor([0.5186, 0.7906, 0.9465])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 100%|██████████| 645976/645976 [01:11<00:00, 9091.51ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n",
      "train loss:  76%|███████▌  | 491008/645976 [00:53<00:16, 9136.27ex/s, cont=0.0000, loss=3, loss_time=0, reg=1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ac47f7d46044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         )\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratche/home/apoorv/Temporal_KGQA/tkbc/optimizers.py\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mb_begin\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratche/home/apoorv/Temporal_KGQA/tkgqa_env/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratche/home/apoorv/Temporal_KGQA/tkgqa_env/lib/python3.7/site-packages/torch/optim/adagrad.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     88\u001b[0m                       \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                       \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                       group['eps'])\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratche/home/apoorv/Temporal_KGQA/tkgqa_env/lib/python3.7/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madagrad\u001b[0;34m(params, grads, state_sums, state_steps, lr, weight_decay, lr_decay, eps)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the update is non-linear so indices must be unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mgrad_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mgrad_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in range(args.max_epochs):\n",
    "    examples = torch.from_numpy(\n",
    "        dataset.get_train().astype('int64')\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    if dataset.has_intervals():\n",
    "        optimizer = IKBCOptimizer(\n",
    "            model, emb_reg, time_reg, opt, dataset,\n",
    "            batch_size=args.batch_size\n",
    "        )\n",
    "        optimizer.epoch(examples)\n",
    "\n",
    "    else:\n",
    "        optimizer = TKBCOptimizer(\n",
    "            model, emb_reg, time_reg, opt,\n",
    "            batch_size=args.batch_size\n",
    "        )\n",
    "        optimizer.epoch(examples)\n",
    "\n",
    "\n",
    "    def avg_both(mrrs: Dict[str, float], hits: Dict[str, torch.FloatTensor]):\n",
    "        \"\"\"\n",
    "        aggregate metrics for missing lhs and rhs\n",
    "        :param mrrs: d\n",
    "        :param hits:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        m = (mrrs['lhs'] + mrrs['rhs']) / 2.\n",
    "        h = (hits['lhs'] + hits['rhs']) / 2.\n",
    "        return {'MRR': m, 'hits@[1,3,10]': h}\n",
    "\n",
    "    if epoch < 0 or (epoch + 1) % args.valid_freq == 0:\n",
    "        if dataset.has_intervals():\n",
    "            valid, test, train = [\n",
    "                dataset.eval(model, split, -1 if split != 'train' else 50000)\n",
    "                for split in ['valid', 'test', 'train']\n",
    "            ]\n",
    "            print(\"valid: \", valid)\n",
    "            print(\"test: \", test)\n",
    "            print(\"train: \", train)\n",
    "\n",
    "        else:\n",
    "            valid, test, train = [\n",
    "                avg_both(*dataset.eval(model, split, -1 if split != 'train' else 50000))\n",
    "                for split in ['valid', 'test', 'train']\n",
    "            ]\n",
    "            print(\"valid: \", valid['MRR'])\n",
    "            print(\"test: \", test['MRR'])\n",
    "            print(\"train: \", train['MRR'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "path = 'tkbc_complex_23jan.ckpt'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TemporalDataset(args.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60118, 208, 60118, 1139)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_tkbc_60kent.ckpt'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60118"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['embeddings.0.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['embeddings.1.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1139"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['embeddings.2.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "# path = 'model.ckpt'\n",
    "# model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/scratche/home/apoorv/tkbc/tkbc_env/lib/python3.7/site-packages/tkbc-0.0.0-py3.7.egg/tkbc/data/wikidata_small/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TComplEx(\n",
      "  (embeddings): ModuleList(\n",
      "    (0): Embedding(60118, 512, sparse=True)\n",
      "    (1): Embedding(208, 512, sparse=True)\n",
      "    (2): Embedding(1139, 512, sparse=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dicts = {}\n",
    "for f in ['ent_id', 'rel_id', 'ts_id']:\n",
    "    in_file = open(str(base_path + f), 'rb')\n",
    "    dicts[f] = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id = dicts['rel_id']\n",
    "ent2id = dicts['ent_id']\n",
    "ts2id = dicts['ts_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need wikidata_ids -> text for ent and rel, for human interpretability\n",
    "# year_ids -> year is already there\n",
    "file_ent = '/scratche/home/apoorv/tempqa/data/temporal_small/entity2wd_id.txt'\n",
    "file_rel = '/scratche/home/apoorv/tempqa/data/temporal_small/relation2wd_id.txt'\n",
    "\n",
    "def readDict(filename):\n",
    "    f = open(filename, 'r')\n",
    "    d = {}\n",
    "    for line in f:\n",
    "        line = line.strip().split('\\t')\n",
    "        d[line[0]] = line[1]\n",
    "    f.close()\n",
    "    return d\n",
    "\n",
    "e = readDict(file_ent)\n",
    "r = readDict(file_rel)\n",
    "wd_id_to_text = dict(list(e.items()) + list(r.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReverseDict(d):\n",
    "    return {value: key for key, value in d.items()}\n",
    "\n",
    "def dataIdsToLiterals(d, all_dicts):\n",
    "    new_datapoint = []\n",
    "    id2rel = all_dicts['id2rel']\n",
    "    id2ent = all_dicts['id2ent']\n",
    "    id2ts = all_dicts['id2ts']\n",
    "    wd_id_to_text = all_dicts['wd_id_to_text']\n",
    "    new_datapoint.append(wd_id_to_text[id2ent[d[0]]])\n",
    "    new_datapoint.append(wd_id_to_text[id2rel[d[1]]])\n",
    "    new_datapoint.append(wd_id_to_text[id2ent[d[2]]])\n",
    "    new_datapoint.append(id2ts[d[3]])\n",
    "    new_datapoint.append(id2ts[d[4]])\n",
    "    return new_datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2rel = getReverseDict(rel2id)\n",
    "id2ent = getReverseDict(ent2id)\n",
    "id2ts = getReverseDict(ts2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dicts = {'rel2id': rel2id,\n",
    "             'id2rel': id2rel,\n",
    "             'ent2id': ent2id,\n",
    "             'id2ent': id2ent,\n",
    "             'ts2id': ts2id,\n",
    "             'id2ts': id2ts,\n",
    "             'wd_id_to_text': wd_id_to_text\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Q100', 0),\n",
       " ('Q1000051', 1),\n",
       " ('Q1000061', 2),\n",
       " ('Q1000104', 3),\n",
       " ('Q100028', 4)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ent2id.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Simone Perrotta',\n",
       " 'member of sports team',\n",
       " 'Juventus F.C.',\n",
       " (1998, 0, 0),\n",
       " (1999, 0, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataIdsToLiterals(d, all_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_in_batch = 10\n",
    "test_batch = torch.from_numpy(\n",
    "        dataset.get_examples('train').astype('int64')\n",
    "    )\n",
    "test_batch = test_batch[:num_in_batch]\n",
    "test_batch = test_batch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TComplEx(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(60118, 512, sparse=True)\n",
       "    (1): Embedding(208, 512, sparse=True)\n",
       "    (2): Embedding(1139, 512, sparse=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, factors, time = model.forward(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, ind = torch.max(predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6579\n",
      "21478\n",
      "27199\n",
      "58055\n",
      "15563\n",
      "20002\n",
      "48626\n",
      "14195\n",
      "20849\n",
      "39177\n"
     ]
    }
   ],
   "source": [
    "for x in ind:\n",
    "    print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17762,    80,  6579,  1110,  1111],\n",
      "        [ 6995,    80, 21478,  1083,  1084],\n",
      "        [14149,    80, 27199,  1043,  1043],\n",
      "        [18883,    80, 49196,  1103,  1114],\n",
      "        [21241,    80, 15563,  1122,  1122],\n",
      "        [30460,    80, 20002,  1083,  1084],\n",
      "        [27233,    80, 48626,  1039,  1042],\n",
      "        [46143,    80,  2255,  1111,  1117],\n",
      "        [49617,    80, 20849,  1121,  1124],\n",
      "        [37085,    80, 39177,  1006,  1006]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Simone Perrotta', 'member of sports team', 'Juventus F.C.', (1998, 0, 0), (1999, 0, 0)]\n",
      "['Antonio Bordon', 'member of sports team', 'Udinese Calcio', (1971, 0, 0), (1972, 0, 0)]\n",
      "['Danny Liddle', 'member of sports team', 'Scotland national football team', (1931, 0, 0), (1931, 0, 0)]\n",
      "['Demetrio Albertini', 'member of sports team', 'Italy national football team', (1991, 0, 0), (2002, 0, 0)]\n",
      "['Franco Zuculini', 'member of sports team', 'Genoa Cricket and Football Club', (2010, 0, 0), (2010, 0, 0)]\n",
      "['Franco Tripodi', 'member of sports team', 'S.S. Lazio', (1971, 0, 0), (1972, 0, 0)]\n",
      "['Raffaele Costantino', 'member of sports team', 'F.C. Bari 1908', (1927, 0, 0), (1930, 0, 0)]\n",
      "['Jamie McMaster', 'member of sports team', 'Leeds United F.C.', (1999, 0, 0), (2005, 0, 0)]\n",
      "['Michael Bryan', 'member of sports team', 'Watford F.C.', (2009, 0, 0), (2012, 0, 0)]\n",
      "['Alf Edge', 'member of sports team', 'Manchester City F.C.', (1894, 0, 0), (1894, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "for x in test_batch:\n",
    "    print(dataIdsToLiterals(x.detach().cpu().numpy(), all_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scores = model.forward_over_time(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, ind = torch.topk(time_scores, 1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1111], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 \n",
      "1971 \n",
      "1931 \n",
      "1991 \n",
      "2010 \n",
      "1973 \n",
      "1932 \n",
      "2004 \n",
      "2011 \n",
      "1894 \n"
     ]
    }
   ],
   "source": [
    "for row in ind:\n",
    "    years_string = \"\"\n",
    "    for x in row:\n",
    "        years_string += str(id2ts[x.item()][0]) + ' '\n",
    "    print(years_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Simone Perrotta', 'member of sports team', 'Juventus F.C.', (1998, 0, 0), (1999, 0, 0)]\n",
      "['Antonio Bordon', 'member of sports team', 'Udinese Calcio', (1971, 0, 0), (1972, 0, 0)]\n",
      "['Danny Liddle', 'member of sports team', 'Scotland national football team', (1931, 0, 0), (1931, 0, 0)]\n",
      "['Demetrio Albertini', 'member of sports team', 'Italy national football team', (1991, 0, 0), (2002, 0, 0)]\n",
      "['Franco Zuculini', 'member of sports team', 'Genoa Cricket and Football Club', (2010, 0, 0), (2010, 0, 0)]\n",
      "['Franco Tripodi', 'member of sports team', 'S.S. Lazio', (1971, 0, 0), (1972, 0, 0)]\n",
      "['Raffaele Costantino', 'member of sports team', 'F.C. Bari 1908', (1927, 0, 0), (1930, 0, 0)]\n",
      "['Jamie McMaster', 'member of sports team', 'Leeds United F.C.', (1999, 0, 0), (2005, 0, 0)]\n",
      "['Michael Bryan', 'member of sports team', 'Watford F.C.', (2009, 0, 0), (2012, 0, 0)]\n",
      "['Alf Edge', 'member of sports team', 'Manchester City F.C.', (1894, 0, 0), (1894, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "for x in test_batch:\n",
    "    print(dataIdsToLiterals(x.detach().cpu().numpy(), all_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# questions = pickle.load(open('/scratche/home/apoorv/tempqa/data/questions/questions_position_held_small_with_paraphrases.pickle', 'rb'))\n",
    "# questions = pickle.load(open('/scratche/home/apoorv/tempqa/data/questions/questions_position_held_small_with_paraphrases_v2.pickle', 'rb'))\n",
    "questions = pickle.load(open('/scratche/home/apoorv/tempqa/data/questions/questions_position_held_small_1_paraphrases.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# questions_shuffled = questions.copy()\n",
    "# random.shuffle(questions_shuffled)\n",
    "# fname = '/scratche/home/apoorv/tempqa/data/questions/questions_position_held_small_1_paraphrases_shuffled.pickle'\n",
    "# pickle.dump(questions_shuffled, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/scratche/home/apoorv/tempqa/data/questions/questions_position_held_small_1_paraphrases_shuffled.pickle'\n",
    "questions = pickle.load(open(fname, 'rb'))\n",
    "# questions = pickle.load(open('/scratche/home/apoorv/tempqa/data/questions/questions_position_held_small_with_paraphrases_v2_shuffled.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57954"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def checkQuestion(question, target_template):\n",
    "    template = question['template']\n",
    "    if target_template != template:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# def getDataPoint(question, all_dicts):\n",
    "\n",
    "def predictTime(question, model, all_dicts, k=1):\n",
    "    entities = list(question['entities'])\n",
    "    times = question['times']\n",
    "    target_template = 'When did {head} hold the position of {tail}?'\n",
    "    if checkQuestion(question, target_template) == False:\n",
    "        print('Not time question')\n",
    "        return set()\n",
    "    ent2id = all_dicts['ent2id']\n",
    "    rel2id = all_dicts['rel2id']\n",
    "    id2ts = all_dicts['id2ts']\n",
    "    ent1 = entities[0]\n",
    "    ent2 = entities[1]\n",
    "    text = question['question']\n",
    "    if text.find(ent1) < text.find(ent2):\n",
    "        head = ent2id[ent1]\n",
    "        tail = ent2id[ent2]\n",
    "    else:\n",
    "        head = ent2id[ent2]\n",
    "        tail = ent2id[ent1]\n",
    "    relation = rel2id[list(question['relations'])[0]]\n",
    "    data_point = [head, relation, tail, 1, 1]\n",
    "    data_batch = torch.from_numpy(np.array([data_point])).cuda()\n",
    "    time_scores = model.forward_over_time(data_batch)\n",
    "    val, ind = torch.topk(time_scores, k, dim=1)\n",
    "    topk_set = set()\n",
    "    for row in ind:\n",
    "        for x in row:\n",
    "            topk_set.add(id2ts[x.item()][0])\n",
    "    return topk_set\n",
    "\n",
    "def predictHead(question, model, all_dicts, k=1):\n",
    "    entities = list(question['entities'])\n",
    "    times = list(question['times'])\n",
    "    target_template = 'Who was the {tail} in {time}?'\n",
    "    if checkQuestion(question, target_template) == False:\n",
    "        print('Not time question')\n",
    "        return set()\n",
    "    ent2id = all_dicts['ent2id']\n",
    "    rel2id = all_dicts['rel2id']\n",
    "    ts2id = all_dicts['ts2id']\n",
    "    id2ent = all_dicts['id2ent']\n",
    "    head = ent2id[entities[0]]\n",
    "    try:\n",
    "        time = ts2id[(times[0],0,0)]\n",
    "    except:\n",
    "        return set()\n",
    "    relation = rel2id[list(question['relations'])[0]] + model.embeddings[1].weight.shape[0]//2#+ 90\n",
    "    data_point = [head, relation, 1, time, time]\n",
    "    data_batch = torch.from_numpy(np.array([data_point])).cuda()\n",
    "    predictions, factors, time = model.forward(data_batch)\n",
    "    val, ind = torch.topk(predictions, k, dim=1)\n",
    "    topk_set = set()\n",
    "    for row in ind:\n",
    "        for x in row:\n",
    "            topk_set.add(id2ent[x.item()])\n",
    "    return topk_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57954/57954 [00:10<00:00, 5492.44it/s]\n",
      "  1%|          | 520/57954 [00:00<00:11, 5142.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictHead 8408 8603 0.9773334883180286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57954/57954 [00:11<00:00, 5184.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictTime 12224 12272 0.9960886571056062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "for question_type in ['predictHead', 'predictTime']:\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    k = 1 # hit at k\n",
    "    for i in tqdm(range(len(questions))):\n",
    "        question_template = questions[i]['template']\n",
    "        if question_type == 'predictHead':\n",
    "            which_question_function = predictHead\n",
    "            target_template = 'Who was the {tail} in {time}?'\n",
    "        elif question_type == 'predictTime':\n",
    "            which_question_function = predictTime\n",
    "            target_template = 'When did {head} hold the position of {tail}?'            \n",
    "        if question_template != target_template:\n",
    "            continue\n",
    "        total_count += 1\n",
    "        id = i   \n",
    "        predicted = which_question_function(questions[id], model, all_dicts, k)\n",
    "        intersection_set = questions[id]['answers'].intersection(predicted)\n",
    "        if len(intersection_set) > 0:\n",
    "            correct_count += 1\n",
    "    \n",
    "    print(question_type, correct_count, total_count, correct_count/total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57954"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'When did the first Q11902879 come to power?',\n",
       " 'answers': {1854},\n",
       " 'answer_type': 'time',\n",
       " 'template': 'When did the {adj} {tail} come to power?',\n",
       " 'entities': {'Q11902879'},\n",
       " 'times': set(),\n",
       " 'relations': {'P39'},\n",
       " 'paraphrases': ['When did the first Lord Mayor come to power?']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'When was the first time that Q69036 was the Q30263013?',\n",
       "  'answers': {2012},\n",
       "  'answer_type': 'time',\n",
       "  'template': 'When was the {adj} time that {head} was the {tail}?',\n",
       "  'entities': {'Q30263013', 'Q69036'},\n",
       "  'times': set(),\n",
       "  'relations': {'P39'},\n",
       "  'paraphrases': ['When was the first time that Torsten Albig was the Minister-President of Schleswig-Holstein?']},\n",
       " {'question': 'Who was the Q17014422 in 1982?',\n",
       "  'answers': {'Q2625332', 'Q2748845'},\n",
       "  'answer_type': 'entity',\n",
       "  'template': 'Who was the {tail} in {time}?',\n",
       "  'entities': {'Q17014422'},\n",
       "  'times': {1982},\n",
       "  'relations': {'P39'},\n",
       "  'paraphrases': ['Who was the President of the Congress of Deputies in 1982?']},\n",
       " {'question': 'Who was the Q2484309 in 1802?',\n",
       "  'answers': {'Q337864'},\n",
       "  'answer_type': 'entity',\n",
       "  'template': 'Who was the {tail} in {time}?',\n",
       "  'entities': {'Q2484309'},\n",
       "  'times': {1802},\n",
       "  'relations': {'P39'},\n",
       "  'paraphrases': ['Who was the Secretary of State for the Home Department in 1802?']},\n",
       " {'question': 'When did Q775070 hold the position of Q786242?',\n",
       "  'answers': {1953, 1954, 1955, 1956, 1957, 1958},\n",
       "  'answer_type': 'time',\n",
       "  'template': 'When did {head} hold the position of {tail}?',\n",
       "  'entities': {'Q775070', 'Q786242'},\n",
       "  'times': set(),\n",
       "  'relations': {'P39'},\n",
       "  'paraphrases': ['When did Sherman Adams hold the position of White House Chief of Staff?']},\n",
       " {'question': 'Who was the Q50389144 before Q8073256?',\n",
       "  'answers': {'Q1383644'},\n",
       "  'answer_type': 'entity',\n",
       "  'template': 'Who was the {tail} {type} {head}?',\n",
       "  'entities': {'Q50389144', 'Q8073256'},\n",
       "  'times': set(),\n",
       "  'relations': {'P39'},\n",
       "  'paraphrases': ['Who was the Minister for Volunteers before Zoe Bettison?']}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_st = SentenceTransformer('distilbert-base-nli-mean-tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer(\n",
       "    (auto_model): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Pooling()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_st.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_length, batch_size, embed_dim\n",
    "src = torch.rand(10, 40, 512)\n",
    "# mask is batch_size*num_heads, seq_length, seq_length\n",
    "mask = torch.ones((40, 10), dtype=torch.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 10])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = transformer_encoder(src, src_key_padding_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'When was the first time that Q6787053 was the Q41582565?',\n",
       " 'answers': {1880},\n",
       " 'answer_type': 'time',\n",
       " 'template': 'When was the {adj} time that {head} was the {tail}?',\n",
       " 'entities': {'Q41582565', 'Q6787053'},\n",
       " 'times': set(),\n",
       " 'relations': {'P39'},\n",
       " 'paraphrases': ['When was the first time that Sir Mathew Wilson, 1st Baronet was the Member of the 22nd Parliament of the United Kingdom?']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0,1,2]\n",
    "y = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x, dtype=torch.long)\n",
    "y = torch.tensor(y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'padding_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-f2e17aee47fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpadding_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'padding_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "padding_tensor([x,y])[0].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_tensor(sequences):\n",
    "    \"\"\"\n",
    "    :param sequences: list of tensors\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num = len(sequences)\n",
    "    max_len = max([s.size(0) for s in sequences])\n",
    "    out_dims = (num, max_len)\n",
    "    out_tensor = sequences[0].data.new(*out_dims).fill_(0)\n",
    "    mask = sequences[0].data.new(*out_dims).fill_(0)\n",
    "    for i, tensor in enumerate(sequences):\n",
    "        length = tensor.size(0)\n",
    "        out_tensor[i, :length] = tensor\n",
    "        mask[i, :length] = 1\n",
    "    return out_tensor, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_emb_matrix = model.embeddings[0].weight.data\n",
    "time_emb_matrix = model.embeddings[2].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22170, 512])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.cat([ent_emb_matrix, time_emb_matrix], dim=0)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "nb_digits = 10\n",
    "# Dummy input that HAS to be 2D for the scatter (you can use view(-1,1) if needed)\n",
    "y = torch.LongTensor(batch_size,2).random_() % nb_digits\n",
    "# One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "y_onehot = torch.FloatTensor(batch_size, nb_digits)\n",
    "\n",
    "# In your for loop\n",
    "y_onehot.zero_()\n",
    "y_onehot.scatter_(1, y, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 8],\n",
       "        [9, 0],\n",
       "        [6, 0],\n",
       "        [7, 1],\n",
       "        [0, 5]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3]), tensor([3, 4, 5])]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([3,4,5])\n",
    "[a,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack([a,b,a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 5],\n",
       "        [1, 2, 3],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot = torch.FloatTensor(4, 20)\n",
    "\n",
    "# In your for loop\n",
    "y_onehot.zero_()\n",
    "y_onehot.scatter_(1, x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 512])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.embeddings[0](x.cuda())\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.FloatTensor(4, 512).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 512])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat([b,a], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 512])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.BoolTensor((10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros((4, 10), dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
