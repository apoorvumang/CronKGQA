{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# facts = pickle.load(open('wikidata_text_facts.txt', 'rb'))\n",
    "# facts = pickle.load(open('text_facts_v2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntsFromFacts(facts):\n",
    "    e = set()\n",
    "    for f in facts:\n",
    "        e.add(f[0])\n",
    "        e.add(f[2])\n",
    "    return e\n",
    "\n",
    "def readFile(filename):\n",
    "    f = open(filename, 'r')\n",
    "    lines = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line != '':\n",
    "            lines.append(line)\n",
    "    f.close()\n",
    "    return lines\n",
    "\n",
    "def getRelsFromFacts(facts):\n",
    "    r = set()\n",
    "    for f in facts:\n",
    "        r.add(f[1])\n",
    "    return r\n",
    "\n",
    "def filterByRelation(facts, rel, max=50):\n",
    "    filtered = []\n",
    "    count = 0\n",
    "    for f in facts:\n",
    "        if f[1] == rel:\n",
    "            filtered.append(f)\n",
    "            count += 1\n",
    "        if max < 0:\n",
    "            continue\n",
    "        if count >= max:\n",
    "            break\n",
    "    return filtered\n",
    "\n",
    "def filterByHead(facts, head, max=50):\n",
    "    filtered = []\n",
    "    count = 0\n",
    "    for f in facts:\n",
    "        if f[0] == head:\n",
    "            filtered.append(f)\n",
    "            count += 1\n",
    "        if max < 0:\n",
    "            continue\n",
    "        if count >= max:\n",
    "            break\n",
    "    return filtered\n",
    "\n",
    "def filterByTail(facts, tail, max=50):\n",
    "    filtered = []\n",
    "    count = 0\n",
    "    for f in facts:\n",
    "        if f[2] == tail:\n",
    "            filtered.append(f)\n",
    "            count += 1\n",
    "        if max < 0:\n",
    "            continue\n",
    "        if count >= max:\n",
    "            break\n",
    "    return filtered\n",
    "\n",
    "def filterByEntity(facts, ent, max=50):\n",
    "    filtered = []\n",
    "    count = 0\n",
    "    for f in facts:\n",
    "        if f[0] == ent or f[2] == ent:\n",
    "            filtered.append(f)\n",
    "            count += 1\n",
    "        if max < 0:\n",
    "            continue\n",
    "        if count >= max:\n",
    "            break\n",
    "    return filtered\n",
    "\n",
    "def printFact(f):\n",
    "    s = \"{head}, {rel}, {tail}, {t1}, {t2}\"\n",
    "    head=f[0]\n",
    "    rel = f[1]\n",
    "    tail = f[2]\n",
    "    t1 = f[3][1:5]\n",
    "    t2 = f[4][1:5]\n",
    "    print(s.format(head=head, rel=rel, tail=tail, t1=t1, t2=t2))\n",
    "    \n",
    "def printFacts(facts):\n",
    "    for f in facts:\n",
    "        printFact(f)\n",
    "        \n",
    "def isEntityInFact(e, fact):\n",
    "    if fact[0] == e or fact[2] == e:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "        \n",
    "def writeFactsToFile(filename, facts):\n",
    "    f = open(filename, 'w')\n",
    "    for fact in facts:\n",
    "        line = '\\t'.join(fact)\n",
    "        f.write(line + '\\n')\n",
    "    f.close()\n",
    "    \n",
    "def readFactsFromFile(filename):\n",
    "    f = open(filename, 'r')\n",
    "    facts = []\n",
    "    for line in f:\n",
    "        fact = line.strip().split('\\t')\n",
    "        facts.append(fact)\n",
    "    f.close()\n",
    "    return facts\n",
    "\n",
    "def createWikidataIdentifierToTextDict(entities, relations):\n",
    "    ent_rel_both = {}\n",
    "    ent_rel_both['Q'] = entities\n",
    "    ent_rel_both['P'] = relations\n",
    "    wikidata_id2name = {}\n",
    "    count = 0\n",
    "    for prefix, lines in ent_rel_both.items():\n",
    "        for line in lines:\n",
    "            try:\n",
    "                line = line.split('\\t')\n",
    "                id = prefix + line[1] #different from one above\n",
    "                name = line[2]\n",
    "                wikidata_id2name[id] = name\n",
    "            except:\n",
    "                id = prefix + line[1]\n",
    "                name = ''\n",
    "                wikidata_id2name[id] = name\n",
    "    return wikidata_id2name\n",
    "\n",
    "def convertFactToText(fact, wikidata_identifier_to_text):\n",
    "    f = fact.copy()\n",
    "    for i in range(3):\n",
    "        f[i] = wikidata_identifier_to_text[fact[i]]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = readFactsFromFile('../data/temporal_big/full.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = getRelsFromFacts(facts)\n",
    "e = getEntsFromFacts(facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_count_dict = {}\n",
    "r_count_dict = {}\n",
    "head_count = {}\n",
    "tail_count = {}\n",
    "for ent in e:\n",
    "    e_count_dict[ent] = 0\n",
    "    head_count[ent] = 0\n",
    "    tail_count[ent] = 0\n",
    "for rel in r:\n",
    "    r_count_dict[rel] = 0\n",
    "for f in facts:\n",
    "    e1 = f[0]\n",
    "    e2 = f[2]\n",
    "    rel = f[1]\n",
    "    e_count_dict[e1] += 1\n",
    "    e_count_dict[e2] += 1\n",
    "    r_count_dict[rel] += 1\n",
    "    head_count[e1] += 1\n",
    "    tail_count[e2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = r_count_dict\n",
    "sorted_r = {k: v for k, v in sorted(x.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "x = e_count_dict\n",
    "sorted_e = {k: v for k, v in sorted(x.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "x = head_count\n",
    "sorted_head = {k: v for k, v in sorted(x.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "x = tail_count\n",
    "sorted_tail = {k: v for k, v in sorted(x.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P39 | 78380 facts 23.85 %\n",
      "P166 | 75474 facts 22.97 %\n",
      "P54 | 67007 facts 20.39 %\n",
      "P1411 | 21983 facts 6.69 %\n",
      "P1346 | 17841 facts 5.43 %\n",
      "P793 | 9463 facts 2.88 %\n",
      "P26 | 6034 facts 1.84 %\n",
      "P108 | 5448 facts 1.66 %\n",
      "P937 | 4795 facts 1.46 %\n",
      "P69 | 4424 facts 1.35 %\n",
      "P512 | 3821 facts 1.16 %\n",
      "P17 | 2604 facts 0.79 %\n",
      "P131 | 2327 facts 0.71 %\n",
      "P106 | 1669 facts 0.51 %\n",
      "P463 | 1605 facts 0.49 %\n",
      "P551 | 1407 facts 0.43 %\n",
      "P150 | 1355 facts 0.41 %\n",
      "P6 | 1310 facts 0.4 %\n",
      "P410 | 1306 facts 0.4 %\n",
      "P102 | 1239 facts 0.38 %\n",
      "P488 | 1154 facts 0.35 %\n",
      "P241 | 1112 facts 0.34 %\n",
      "P185 | 1045 facts 0.32 %\n",
      "P27 | 872 facts 0.27 %\n",
      "P527 | 867 facts 0.26 %\n",
      "P286 | 866 facts 0.26 %\n",
      "P31 | 676 facts 0.21 %\n",
      "P5008 | 654 facts 0.2 %\n",
      "P127 | 596 facts 0.18 %\n",
      "P1308 | 562 facts 0.17 %\n",
      "P184 | 544 facts 0.17 %\n",
      "P451 | 519 facts 0.16 %\n",
      "P1037 | 490 facts 0.15 %\n",
      "P361 | 467 facts 0.14 %\n",
      "P2079 | 466 facts 0.14 %\n",
      "P195 | 382 facts 0.12 %\n",
      "P35 | 377 facts 0.11 %\n",
      "P1075 | 349 facts 0.11 %\n",
      "P607 | 335 facts 0.1 %\n",
      "P840 | 334 facts 0.1 %\n",
      "P598 | 280 facts 0.09 %\n",
      "P276 | 265 facts 0.08 %\n",
      "P1416 | 261 facts 0.08 %\n",
      "P1344 | 260 facts 0.08 %\n",
      "P1891 | 255 facts 0.08 %\n",
      "P366 | 251 facts 0.08 %\n",
      "P4791 | 244 facts 0.07 %\n",
      "P5096 | 205 facts 0.06 %\n",
      "P1029 | 203 facts 0.06 %\n",
      "P119 | 198 facts 0.06 %\n",
      "P137 | 174 facts 0.05 %\n",
      "P945 | 173 facts 0.05 %\n",
      "P411 | 168 facts 0.05 %\n",
      "P608 | 165 facts 0.05 %\n",
      "P97 | 158 facts 0.05 %\n",
      "P118 | 155 facts 0.05 %\n",
      "P36 | 149 facts 0.05 %\n",
      "P710 | 132 facts 0.04 %\n",
      "P1399 | 132 facts 0.04 %\n",
      "P47 | 110 facts 0.03 %\n",
      "P1376 | 109 facts 0.03 %\n",
      "P138 | 106 facts 0.03 %\n",
      "P1454 | 105 facts 0.03 %\n",
      "P190 | 94 facts 0.03 %\n",
      "P159 | 86 facts 0.03 %\n",
      "P6087 | 83 facts 0.03 %\n",
      "P175 | 78 facts 0.02 %\n",
      "P1347 | 77 facts 0.02 %\n",
      "P3975 | 75 facts 0.02 %\n",
      "P647 | 70 facts 0.02 %\n",
      "P2632 | 69 facts 0.02 %\n",
      "P5021 | 65 facts 0.02 %\n",
      "P1050 | 64 facts 0.02 %\n",
      "P2522 | 61 facts 0.02 %\n",
      "P172 | 59 facts 0.02 %\n",
      "P264 | 56 facts 0.02 %\n",
      "P1066 | 56 facts 0.02 %\n",
      "P1365 | 50 facts 0.02 %\n",
      "P1366 | 49 facts 0.01 %\n",
      "P449 | 44 facts 0.01 %\n",
      "P169 | 44 facts 0.01 %\n",
      "P803 | 43 facts 0.01 %\n",
      "P504 | 41 facts 0.01 %\n",
      "P2936 | 37 facts 0.01 %\n",
      "P122 | 35 facts 0.01 %\n",
      "P915 | 32 facts 0.01 %\n",
      "P101 | 30 facts 0.01 %\n",
      "P749 | 29 facts 0.01 %\n",
      "P800 | 29 facts 0.01 %\n",
      "P156 | 27 facts 0.01 %\n",
      "P140 | 27 facts 0.01 %\n",
      "P2629 | 26 facts 0.01 %\n",
      "P98 | 26 facts 0.01 %\n",
      "P371 | 25 facts 0.01 %\n",
      "P1596 | 24 facts 0.01 %\n",
      "P1327 | 21 facts 0.01 %\n",
      "P155 | 21 facts 0.01 %\n",
      "P2416 | 20 facts 0.01 %\n",
      "P466 | 18 facts 0.01 %\n",
      "P609 | 17 facts 0.01 %\n",
      "P355 | 15 facts 0.0 %\n",
      "P530 | 15 facts 0.0 %\n",
      "P1923 | 14 facts 0.0 %\n",
      "P611 | 13 facts 0.0 %\n",
      "P279 | 13 facts 0.0 %\n",
      "P505 | 12 facts 0.0 %\n",
      "P802 | 12 facts 0.0 %\n",
      "P1038 | 11 facts 0.0 %\n",
      "P734 | 11 facts 0.0 %\n",
      "P641 | 10 facts 0.0 %\n",
      "P1444 | 10 facts 0.0 %\n",
      "P1427 | 10 facts 0.0 %\n",
      "P750 | 9 facts 0.0 %\n",
      "P421 | 9 facts 0.0 %\n",
      "P3342 | 9 facts 0.0 %\n",
      "P3320 | 9 facts 0.0 %\n",
      "P725 | 9 facts 0.0 %\n",
      "P3919 | 9 facts 0.0 %\n",
      "P3195 | 8 facts 0.0 %\n",
      "P1532 | 8 facts 0.0 %\n",
      "P511 | 8 facts 0.0 %\n",
      "P634 | 7 facts 0.0 %\n",
      "P178 | 7 facts 0.0 %\n",
      "P84 | 7 facts 0.0 %\n",
      "P859 | 7 facts 0.0 %\n",
      "P88 | 7 facts 0.0 %\n",
      "P123 | 7 facts 0.0 %\n",
      "P37 | 7 facts 0.0 %\n",
      "P1027 | 7 facts 0.0 %\n",
      "P115 | 7 facts 0.0 %\n",
      "P400 | 7 facts 0.0 %\n",
      "P180 | 7 facts 0.0 %\n",
      "P735 | 6 facts 0.0 %\n",
      "P1598 | 6 facts 0.0 %\n",
      "P812 | 6 facts 0.0 %\n",
      "P832 | 6 facts 0.0 %\n",
      "P1657 | 6 facts 0.0 %\n",
      "P1830 | 6 facts 0.0 %\n",
      "P57 | 6 facts 0.0 %\n",
      "P2643 | 6 facts 0.0 %\n",
      "P186 | 5 facts 0.0 %\n",
      "P509 | 5 facts 0.0 %\n",
      "P4353 | 5 facts 0.0 %\n",
      "P170 | 5 facts 0.0 %\n",
      "P40 | 5 facts 0.0 %\n",
      "P2500 | 5 facts 0.0 %\n",
      "P1336 | 5 facts 0.0 %\n",
      "P1981 | 5 facts 0.0 %\n",
      "P726 | 5 facts 0.0 %\n",
      "P38 | 4 facts 0.0 %\n",
      "P1001 | 4 facts 0.0 %\n",
      "P2868 | 4 facts 0.0 %\n",
      "P1303 | 4 facts 0.0 %\n",
      "P112 | 4 facts 0.0 %\n",
      "P706 | 4 facts 0.0 %\n",
      "P740 | 4 facts 0.0 %\n",
      "P1906 | 4 facts 0.0 %\n",
      "P1884 | 3 facts 0.0 %\n",
      "P61 | 3 facts 0.0 %\n",
      "P770 | 3 facts 0.0 %\n",
      "P2758 | 3 facts 0.0 %\n",
      "P495 | 3 facts 0.0 %\n",
      "P748 | 3 facts 0.0 %\n",
      "P2438 | 3 facts 0.0 %\n",
      "P972 | 3 facts 0.0 %\n",
      "P413 | 3 facts 0.0 %\n",
      "P414 | 3 facts 0.0 %\n",
      "P162 | 3 facts 0.0 %\n",
      "P86 | 2 facts 0.0 %\n",
      "P1196 | 2 facts 0.0 %\n",
      "P19 | 2 facts 0.0 %\n",
      "P20 | 2 facts 0.0 %\n",
      "P136 | 2 facts 0.0 %\n",
      "P737 | 2 facts 0.0 %\n",
      "P1035 | 2 facts 0.0 %\n",
      "P176 | 2 facts 0.0 %\n",
      "P1343 | 2 facts 0.0 %\n",
      "P272 | 2 facts 0.0 %\n",
      "P1435 | 2 facts 0.0 %\n",
      "P6364 | 2 facts 0.0 %\n",
      "P2388 | 2 facts 0.0 %\n",
      "P121 | 2 facts 0.0 %\n",
      "P541 | 2 facts 0.0 %\n",
      "P450 | 2 facts 0.0 %\n",
      "P2596 | 1 facts 0.0 %\n",
      "P5389 | 1 facts 0.0 %\n",
      "P21 | 1 facts 0.0 %\n",
      "P2962 | 1 facts 0.0 %\n",
      "P664 | 1 facts 0.0 %\n",
      "P2499 | 1 facts 0.0 %\n",
      "P1455 | 1 facts 0.0 %\n",
      "P3095 | 1 facts 0.0 %\n",
      "P1313 | 1 facts 0.0 %\n",
      "P291 | 1 facts 0.0 %\n",
      "P2348 | 1 facts 0.0 %\n",
      "P1576 | 1 facts 0.0 %\n",
      "P1542 | 1 facts 0.0 %\n",
      "P852 | 1 facts 0.0 %\n",
      "P1441 | 1 facts 0.0 %\n",
      "P485 | 1 facts 0.0 %\n",
      "P3602 | 1 facts 0.0 %\n",
      "P3085 | 1 facts 0.0 %\n",
      "P3716 | 1 facts 0.0 %\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted_r.items():\n",
    "    print(key, '|', value, 'facts', round(value/len(facts)*100, 2), '%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = 'P108'\n",
    "employerFacts = filterByRelation(facts, rel, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTimeNoNewTimeStamps(facts, timestamps):\n",
    "    # don't introduce new timestamps!\n",
    "    new_facts = []\n",
    "    for f in facts:\n",
    "        e1 = f[0]\n",
    "        r = f[1]\n",
    "        e2 = f[2]\n",
    "        t1 = int(f[3])\n",
    "        t2 = int(f[4])\n",
    "        for t in range(t1, t2+1):\n",
    "            if t in timestamps:\n",
    "                nf = [e1, r, e2, t]\n",
    "                new_facts.append(nf)\n",
    "    return new_facts\n",
    "\n",
    "def splitTime(facts):\n",
    "    # don't introduce new timestamps!\n",
    "    new_facts = []\n",
    "    for f in facts:\n",
    "        e1 = f[0]\n",
    "        r = f[1]\n",
    "        e2 = f[2]\n",
    "        t1 = int(f[3])\n",
    "        t2 = int(f[4])\n",
    "        for t in range(t1, t2+1):\n",
    "            nf = [e1, r, e2, t]\n",
    "            new_facts.append(nf)\n",
    "    return new_facts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "employerFactsSingle = splitTime(employerFacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple questions, time answer\n",
    "def genTimeSimple1(facts, base_fact):\n",
    "    head = base_fact[0]\n",
    "    tail = base_fact[2]\n",
    "    template = \"When was {head} employed at {tail}?\"\n",
    "    answers = set()\n",
    "    for f in facts:\n",
    "        if f[0] == head and f[2] == tail:\n",
    "            answers.add(f[3])\n",
    "    question = template.format(head=head, tail=tail)\n",
    "    answer_type = 'time'\n",
    "    entities = set([head, tail])\n",
    "    times = set()\n",
    "    relations = set(['P108'])\n",
    "    output = {'question': question,\n",
    "             'answers': answers,\n",
    "             'answer_type': answer_type,\n",
    "             'template': template,\n",
    "             'entities': entities,\n",
    "             'times': times,\n",
    "             'relations': relations}\n",
    "    return output\n",
    "\n",
    "        \n",
    "\n",
    "# simple questions, entity answer\n",
    "def genEntitySimple1(facts, head, time):\n",
    "    template = \"Where was {head} employed at in {time}?\"\n",
    "    answers = set()\n",
    "    for f in facts:\n",
    "        if f[0] == head and f[3] == time:\n",
    "            answers.add(f[2])\n",
    "    question = template.format(head=head, time=time)\n",
    "    answer_type = 'entity'\n",
    "    entities = set([head])\n",
    "    times = set([time])\n",
    "    relations = set(['P108'])\n",
    "    output = {'question': question,\n",
    "             'answers': answers,\n",
    "             'answer_type': answer_type,\n",
    "             'template': template,\n",
    "             'entities': entities,\n",
    "             'times': times,\n",
    "             'relations': relations}\n",
    "    return output\n",
    "        \n",
    "\n",
    "# complex question, entity answer\n",
    "def genEntityComplex1(facts, head, first=True):\n",
    "    # first/last\n",
    "    template = \"Who was the {adj} employer of {head}?\"\n",
    "    minTime = 9999\n",
    "    minTeam = \"\"\n",
    "    maxTime = -1\n",
    "    maxTeam = \"\"\n",
    "    answers = set()\n",
    "    for f in facts:\n",
    "        if f[0] == head:\n",
    "            time = f[3]\n",
    "            if time < minTime:\n",
    "                minTime = time\n",
    "            if time > maxTime:\n",
    "                maxTime = time\n",
    "    for f in facts:\n",
    "        if f[0] == head:\n",
    "            time = f[3]\n",
    "            if first==True:\n",
    "                if time==minTime:\n",
    "                    answers.add(f[2])\n",
    "            else:\n",
    "                if time==maxTime:\n",
    "                    answers.add(f[2])\n",
    "    if first==True:\n",
    "        question = template.format(head=head, adj='first')\n",
    "    else:\n",
    "        question = template.format(head=head, adj='last')\n",
    "    answer_type = 'entity'\n",
    "    entities = set([head])\n",
    "    times = set()\n",
    "    relations = set(['P108'])\n",
    "    output = {'question': question,\n",
    "             'answers': answers,\n",
    "             'answer_type': answer_type,\n",
    "             'template': template,\n",
    "             'entities': entities,\n",
    "             'times': times,\n",
    "             'relations': relations}\n",
    "    return output\n",
    "        \n",
    "\n",
    "def getFactWithMaximumTime(facts, head = '', tail = ''):\n",
    "    maxTime = -1\n",
    "    fact = facts[0]\n",
    "    for f in facts:\n",
    "        time = f[-1]\n",
    "        if head != '':\n",
    "            if f[0] != head:\n",
    "                continue\n",
    "        if tail != '':\n",
    "            if f[2] != tail:\n",
    "                continue\n",
    "        if time > maxTime:\n",
    "            maxTime = time\n",
    "            fact = f\n",
    "    return fact\n",
    "\n",
    "def getFactWithMinimumTime(facts, head = '', tail = ''):\n",
    "    minTime = 9999\n",
    "    fact = facts[0]\n",
    "    for f in facts:\n",
    "        time = f[-1]\n",
    "        if head != '':\n",
    "            if f[0] != head:\n",
    "                continue\n",
    "        if tail != '':\n",
    "            if f[2] != tail:\n",
    "                continue\n",
    "        if time < minTime:\n",
    "            minTime = time\n",
    "            fact = f\n",
    "    return fact\n",
    "\n",
    "\n",
    "def genEntityComplex2(facts, head, tail, after=True):\n",
    "    # before/after\n",
    "    #ERROR: Grammar- employed {type}\n",
    "    template = \"Where was {head} employed at {type} {tail}?\"\n",
    "    # before: find argmin(T) (head, r, tail, T)\n",
    "    # then, find argmax(T')(head, r, tail', T'), T' < T and tail' != tail\n",
    "    # tail' is the answer\n",
    "    answers = set()\n",
    "    if after == False:\n",
    "        base_fact = getFactWithMinimumTime(facts, head = head, tail = tail)\n",
    "        time = base_fact[-1]\n",
    "        maxTime = -1\n",
    "        maxTimeFact = []\n",
    "        for f in facts:\n",
    "            time2 = f[-1]\n",
    "            if time2 >= time:\n",
    "                continue\n",
    "            if f[0] != head:\n",
    "                continue\n",
    "            if f[2] == tail:\n",
    "                continue\n",
    "            if time2 > maxTime:\n",
    "                maxTime = time2\n",
    "        answers = set()\n",
    "        for f in facts:\n",
    "            time2 = f[-1]\n",
    "            if f[0] != head:\n",
    "                continue\n",
    "            if f[2] == tail:\n",
    "                continue\n",
    "            if time2 == maxTime:\n",
    "                answers.add(f[2])\n",
    "        question = template.format(head=head, type=\"before\", tail=tail)\n",
    "    else:\n",
    "        #after: find argmax(T) (head, r, tail, T)\n",
    "        # then, find argmin(T') (head, r, tail', T'), T' > T and tail' != tail\n",
    "        # tail' is the answer\n",
    "        base_fact = getFactWithMaximumTime(facts, head = head, tail = tail)\n",
    "        time = base_fact[-1]\n",
    "        minTime = 9999\n",
    "        minTimeFact = []\n",
    "        for f in facts:\n",
    "            time2 = f[-1]\n",
    "            if time2 <= time:\n",
    "                continue\n",
    "            if f[0] != head:\n",
    "                continue\n",
    "            if f[2] == tail:\n",
    "                continue\n",
    "            if time2 < minTime:\n",
    "                minTime = time2\n",
    "        for f in facts:\n",
    "            time2 = f[-1]\n",
    "            if f[0] != head:\n",
    "                continue\n",
    "            if f[2] == tail:\n",
    "                continue\n",
    "            if time2 == minTime:\n",
    "                answers.add(f[2])\n",
    "        question = template.format(head=head, type=\"after\", tail=tail)\n",
    "    answer_type = 'entity'\n",
    "    entities = set([head, tail])\n",
    "    times = set()\n",
    "    relations = set(['P108'])\n",
    "    output = {'question': question,\n",
    "             'answers': answers,\n",
    "             'answer_type': answer_type,\n",
    "             'template': template,\n",
    "             'entities': entities,\n",
    "             'times': times,\n",
    "             'relations': relations}\n",
    "    return output\n",
    "        \n",
    "    \n",
    "    \n",
    "def genEntityComplex3(facts, head, tail):\n",
    "    template = \"Who did {head} work with while employed at {tail}?\"\n",
    "    # first get all time instances when head played for tail\n",
    "    # then get all heads, where tail' = tail and time' in T\n",
    "    valid_times = set()\n",
    "    for f in facts:\n",
    "        if f[0] == head and f[2] == tail:\n",
    "            valid_times.add(f[-1])\n",
    "    answers = set()\n",
    "    for f in facts:\n",
    "        if f[2] == tail and f[-1] in valid_times:\n",
    "            answers.add(f[0])\n",
    "    answers.remove(head)\n",
    "    question = template.format(head=head, tail=tail)\n",
    "    answer_type = 'entity'\n",
    "    entities = set([head, tail])\n",
    "    times = set()\n",
    "    relations = set(['P108'])\n",
    "    output = {'question': question,\n",
    "             'answers': answers,\n",
    "             'answer_type': answer_type,\n",
    "             'template': template,\n",
    "             'entities': entities,\n",
    "             'times': times,\n",
    "             'relations': relations}\n",
    "    return output\n",
    "\n",
    "\n",
    "def areFactsSame(f1, f2):\n",
    "    flag = True\n",
    "    for i in range(3):\n",
    "        if f1[i] != f2[i]:\n",
    "            flag = False\n",
    "            break\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(events_facts)\n",
    "import pickle as pkl\n",
    "def openFileAsDict(filename):\n",
    "    f = open(filename, 'r')\n",
    "    out = {}\n",
    "    for line in f:\n",
    "        line = line[:-1].split('\\t') # can't strip() since name can be whitespace\n",
    "        out[line[0]] = line[1]\n",
    "    return out\n",
    "ent2name = openFileAsDict( '../data/wikidata_big/kg/wd_id2entity_text.txt')\n",
    "rel2name = openFileAsDict( '../data/wikidata_big/kg/wd_id2relation_text.txt')\n",
    "name2ent={i:j for (j,i) in ent2name.items()}\n",
    "name2rel={i:j for (j,i) in rel2name.items()}\n",
    "\n",
    "ent2id=pkl.load(open(\"../data/wikidata_big/kg/tkbc_processed_data/wikidata_big/ent_id\",\"rb\"))\n",
    "rel2id=pkl.load(open(\"../data/wikidata_big/kg/tkbc_processed_data/wikidata_big/rel_id\",\"rb\"))\n",
    "id2ent={i:j for (j,i) in ent2id.items()}\n",
    "id2rel={i:j for (j,i) in rel2id.items()}\n",
    "id2relname={i:rel2name[id2rel[i]] for i in id2rel}\n",
    "id2entname={i:ent2name[id2ent[i]] for i in id2ent}\n",
    "def get_facts_from_entname(entname):\n",
    "    idx=name2ent[entname]\n",
    "    facts_=[]\n",
    "    for fact in events_facts:\n",
    "        if (fact[0]==idx or fact[2]==idx):\n",
    "            fact=(ent2name[fact[0]],rel2name[fact[1]],ent2name[fact[2]],fact[3],fact[4])\n",
    "            facts_.append(fact)\n",
    "            print(fact)\n",
    "    return facts_\n",
    "def get_facts_from_entid(idx):\n",
    "    facts_=[]\n",
    "    for fact in employerFacts:\n",
    "        if (fact[0]==idx or fact[2]==idx):\n",
    "            fact=(ent2name[fact[0]],rel2name[fact[1]],ent2name[fact[2]],fact[3],fact[4])\n",
    "            facts_.append(fact)\n",
    "#             print(fact)\n",
    "    return facts_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Philippa Levine',\n",
       "  'employer',\n",
       "  'University of Southern California',\n",
       "  '1991',\n",
       "  '2010'),\n",
       " ('Philippa Levine', 'employer', 'Florida State University', '1987', '1991'),\n",
       " ('Philippa Levine', 'employer', 'University of East Anglia', '1983', '1985')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_facts_from_entid(\"Q48031813\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'When was Q48031813 employed at Q4614?',\n",
       " 'answers': {1991,\n",
       "  1992,\n",
       "  1993,\n",
       "  1994,\n",
       "  1995,\n",
       "  1996,\n",
       "  1997,\n",
       "  1998,\n",
       "  1999,\n",
       "  2000,\n",
       "  2001,\n",
       "  2002,\n",
       "  2003,\n",
       "  2004,\n",
       "  2005,\n",
       "  2006,\n",
       "  2007,\n",
       "  2008,\n",
       "  2009,\n",
       "  2010},\n",
       " 'answer_type': 'time',\n",
       " 'template': 'When was {head} employed at {tail}?',\n",
       " 'entities': {'Q4614', 'Q48031813'},\n",
       " 'times': set(),\n",
       " 'relations': {'P108'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 1\n",
    "f = employerFactsSingle[id]\n",
    "genTimeSimple1(employerFactsSingle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Philippa Levine',\n",
       "  'employer',\n",
       "  'University of Southern California',\n",
       "  '1991',\n",
       "  '2010'),\n",
       " ('Philippa Levine', 'employer', 'Florida State University', '1987', '1991'),\n",
       " ('Philippa Levine', 'employer', 'University of East Anglia', '1983', '1985')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_facts_from_entid(\"Q48031813\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Where was Q48031813 employed at in 1992?',\n",
       " 'answers': {'Q4614'},\n",
       " 'answer_type': 'entity',\n",
       " 'template': 'Where was {head} employed at in {time}?',\n",
       " 'entities': {'Q48031813'},\n",
       " 'times': {1992},\n",
       " 'relations': {'P108'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genEntitySimple1(employerFactsSingle, f[0], f[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q1045828'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2ent[\"University of East Anglia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Who was the first employer of Q48031813?',\n",
       " 'answers': {'Q1045828'},\n",
       " 'answer_type': 'entity',\n",
       " 'template': 'Who was the {adj} employer of {head}?',\n",
       " 'entities': {'Q48031813'},\n",
       " 'times': set(),\n",
       " 'relations': {'P108'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genEntityComplex1(employerFactsSingle, f[0], first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg_input_output_t5 = []\n",
    "# for f in sportsFacts:\n",
    "#     entry = {}\n",
    "#     head = f[0]\n",
    "#     relation = f[1]\n",
    "#     tail = f[2]\n",
    "#     start_time = f[3][1:5]\n",
    "#     end_time = f[4][1:5]\n",
    "#     input_format = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeQuestions(employerFactsSingle, f):\n",
    "    questions = []\n",
    "    questions.append(genTimeSimple1(employerFactsSingle, f))\n",
    "    questions.append(genEntitySimple1(employerFactsSingle, f[0], f[-1]))\n",
    "    questions.append(genEntityComplex1(employerFactsSingle, f[0], first=random.choice([True, False])))\n",
    "    questions.append(genEntityComplex2(employerFactsSingle, f[0], f[2], after=random.choice([True, False])))\n",
    "    questions.append(genEntityComplex3(employerFactsSingle, f[0], f[2]))\n",
    "    return questions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4919"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "dataset_split = 'test'\n",
    "split_entities = set(pickle.load(open(dataset_split + '_ents.pickle', 'rb')))\n",
    "split_facts = []\n",
    "my_facts = employerFactsSingle\n",
    "for f in my_facts:\n",
    "    if f[0] in split_entities and f[2] in split_entities:\n",
    "        split_facts.append(f)\n",
    "len(split_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to get number of questions?\n",
    "# 1. set total questions to 300k\n",
    "# 2. get number of facts with this relation\n",
    "# 3. get how many questions u want of this relation as fraction\n",
    "# 4. choose 10% of that number for test, 90% for train\n",
    "max_dataset_questions = 300000\n",
    "relation_name = my_facts[0][1]\n",
    "num_relation_facts = len(filterByRelation(facts, relation_name, -1))\n",
    "# fraction of questions need to be decided based on fraction of question relation facts\n",
    "# not all facts!\n",
    "question_relation_list = ['P39', 'P166', 'P108', 'P54', 'P26']\n",
    "num_all_question_relation_facts = sum([len(filterByRelation(facts, x, -1)) for x in question_relation_list])\n",
    "num_questions_for_this_relation = int(max_dataset_questions * num_relation_facts/num_all_question_relation_facts)\n",
    "split_ratios = {'test': 0.1, 'train': 0.9}\n",
    "num_questions = int(split_ratios[dataset_split] * num_questions_for_this_relation)\n",
    "num_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 0, i 0:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 4, i 1:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 8, i 2:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 12, i 3:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 16, i 4:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 20, i 5:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 24, i 6:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 28, i 7:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 32, i 8:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 36, i 9:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 40, i 10:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 43, i 11:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 46, i 12:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 50, i 13:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 53, i 14:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 57, i 15:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 62, i 16:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 67, i 17:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 72, i 18:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 77, i 19:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 81, i 20:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 85, i 21:   0%|          | 0/4919 [00:00<?, ?it/s]\u001b[A\n",
      "Num questions 89, i 22:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 92, i 23:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 97, i 24:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 101, i 25:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 102, i 26:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 104, i 27:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 106, i 28:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 110, i 29:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 114, i 30:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 118, i 31:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 122, i 32:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 125, i 33:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 128, i 34:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 132, i 35:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 136, i 36:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 139, i 37:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 143, i 38:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 148, i 39:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 151, i 40:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 155, i 41:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 158, i 42:   0%|          | 0/4919 [00:01<?, ?it/s]\u001b[A\n",
      "Num questions 161, i 43:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 166, i 44:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 171, i 45:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 176, i 46:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 179, i 47:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 183, i 48:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 188, i 49:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 193, i 50:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 198, i 51:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 202, i 52:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 207, i 53:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 212, i 54:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 216, i 55:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 220, i 56:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 223, i 57:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 228, i 58:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 233, i 59:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 238, i 60:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 242, i 61:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 245, i 62:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 248, i 63:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 252, i 64:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 254, i 65:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 258, i 66:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 260, i 67:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 261, i 68:   0%|          | 0/4919 [00:02<?, ?it/s]\u001b[A\n",
      "Num questions 265, i 69:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 269, i 70:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 273, i 71:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 275, i 72:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 279, i 73:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 280, i 74:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 281, i 75:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 284, i 76:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 289, i 77:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 294, i 78:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 297, i 79:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 300, i 80:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 301, i 81:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 306, i 82:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 311, i 83:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 313, i 84:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 317, i 85:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 321, i 86:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 325, i 87:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 327, i 88:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 331, i 89:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 336, i 90:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 338, i 91:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 342, i 92:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 347, i 93:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 351, i 94:   0%|          | 0/4919 [00:03<?, ?it/s]\u001b[A\n",
      "Num questions 354, i 95:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 355, i 96:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 356, i 97:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 357, i 98:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 359, i 99:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 361, i 100:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 365, i 101:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 366, i 102:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 368, i 103:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 373, i 104:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 376, i 105:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 381, i 106:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 385, i 107:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 389, i 108:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 393, i 109:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 395, i 110:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 397, i 111:   0%|          | 0/4919 [00:04<?, ?it/s]\u001b[A\n",
      "Num questions 400, i 112:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 403, i 113:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 405, i 114:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 410, i 115:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 413, i 116:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 417, i 117:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Num questions 421, i 118:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 422, i 119:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 424, i 120:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 425, i 121:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 429, i 122:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 431, i 123:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 432, i 124:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 437, i 125:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 441, i 126:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 446, i 127:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 450, i 128:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 455, i 129:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 460, i 130:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 464, i 131:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 469, i 132:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 473, i 133:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 477, i 134:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 478, i 135:   0%|          | 0/4919 [00:05<?, ?it/s]\u001b[A\n",
      "Num questions 482, i 136:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 484, i 137:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 486, i 138:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 488, i 139:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 490, i 140:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 492, i 141:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 493, i 142:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 496, i 143:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 499, i 144:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 501, i 145:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 505, i 146:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 509, i 147:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 513, i 148:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 517, i 149:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 522, i 150:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 526, i 151:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 527, i 152:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 532, i 153:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 535, i 154:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 539, i 155:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 542, i 156:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 546, i 157:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 550, i 158:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 552, i 159:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 553, i 160:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 555, i 161:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 559, i 162:   0%|          | 0/4919 [00:06<?, ?it/s]\u001b[A\n",
      "Num questions 562, i 163:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 563, i 164:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 568, i 165:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 573, i 166:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 576, i 167:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 580, i 168:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 585, i 169:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 589, i 170:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 592, i 171:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 593, i 172:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 597, i 173:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 598, i 174:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 601, i 175:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 603, i 176:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 608, i 177:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 609, i 178:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 611, i 179:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 612, i 180:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 617, i 181:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 622, i 182:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 624, i 183:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 628, i 184:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 632, i 185:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 634, i 186:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 636, i 187:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 639, i 188:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 643, i 189:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 645, i 190:   0%|          | 0/4919 [00:07<?, ?it/s]\u001b[A\n",
      "Num questions 646, i 191:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 647, i 192:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 651, i 193:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 655, i 194:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 660, i 195:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 664, i 196:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 668, i 197:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 672, i 198:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 677, i 199:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 681, i 200:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 685, i 201:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 689, i 202:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 693, i 203:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 694, i 204:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 695, i 205:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 699, i 206:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A\n",
      "Num questions 702, i 207:   0%|          | 0/4919 [00:08<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data = []\n",
    "# num_questions = 100000\n",
    "# events_facts_small = events_facts[:10]\n",
    "questions_set = set()\n",
    "\n",
    "pbar = tqdm(range(len(split_facts)))\n",
    "# for i in pbar:\n",
    "random.shuffle(split_facts)\n",
    "for i in range(len(split_facts)):\n",
    "#     f = random.choice(split_facts)\n",
    "    f = split_facts[i]\n",
    "    pbar.set_description(\"Num questions %d, i %d\" % (len(data), i))\n",
    "    questions = makeQuestions(my_facts, f)\n",
    "#     print(questions)\n",
    "#     break\n",
    "    for q in questions:\n",
    "        if len(q['answers']) > 0 and q['question'] not in questions_set:\n",
    "            data.append(q)\n",
    "            questions_set.add(q['question'])\n",
    "    if len(data) >= num_questions:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'When was {head} employed at {tail}?': 154,\n",
       " 'Where was {head} employed at in {time}?': 208,\n",
       " 'Who was the {adj} employer of {head}?': 169,\n",
       " 'Who did {head} work with while employed at {tail}?': 94,\n",
       " 'Where was {head} employed at {type} {tail}?': 78}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getQuestionTypeDistribution(data):\n",
    "    type_dict = {}\n",
    "    for d in data:\n",
    "        template = d['template']\n",
    "        if template not in type_dict:\n",
    "            type_dict[template] = 1\n",
    "        else:\n",
    "            type_dict[template] += 1\n",
    "    return type_dict\n",
    "getQuestionTypeDistribution(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# filename = 'data/questions/questions_employer_big.pickle'\n",
    "filename = 'data/questions/{split}_questions_employer_big.pickle'.format(\n",
    "            split=dataset_split)\n",
    "\n",
    "pickle.dump(data, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    id = random.randint(0, len(sportsFactsSingle))\n",
    "    f = sportsFactsSingle[id]\n",
    "    try:\n",
    "        data += makeQuestions(sportsFactsSingle, f)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeQuestions(filename, data):\n",
    "    f = open(filename, 'w')\n",
    "    for d in data:\n",
    "        answers_str = []\n",
    "        for ans in d[1]:\n",
    "            answers_str.append(str(ans))\n",
    "        if answers_str == []:\n",
    "            continue\n",
    "        line = d[0] + '\\t' + '|'.join(answers_str)\n",
    "        f.write(line + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeQuestions('questions_member_of_sports_team.txt', data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
